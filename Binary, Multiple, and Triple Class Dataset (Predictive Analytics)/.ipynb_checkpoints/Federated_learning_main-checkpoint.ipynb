{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8771e855",
   "metadata": {},
   "source": [
    "This code snippet is a component of a federated learning implementation. Due to client confidentiality and ownership rights, I'm unable to share the complete codebase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff40bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL\n",
    "if args.dataset == 'multi-class':\n",
    "    # defining loss method, optimizer and learning rate\n",
    "    loss = 'sparse_categorical_crossentropy'\n",
    "    metrics = ['accuracy']\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    # initializing global model from the class\n",
    "    mmodel_global = MultiHomoModel()\n",
    "     # build a new model from the function\n",
    "    global_model = mmodel_global.build(89, 37)\n",
    "\n",
    "elif args.dataset == 'triple-class':\n",
    "    # defining loss method, optimizer and learning rate\n",
    "    loss = 'sparse_categorical_crossentropy'\n",
    "    metrics = ['accuracy']\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    # initializing global model from the class\n",
    "    tmodel_global = TripleHomoModel()\n",
    "    # build a new model from the function\n",
    "    global_model = tmodel_global.build(89, 3)\n",
    "\n",
    "elif args.dataset == 'binary-class':\n",
    "    # defining loss method, optimizer and learning rate\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = ['accuracy']\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    # initializing global model from the class\n",
    "    bmodel_global = BinaryHomoModel()\n",
    "    # build a new model from the function\n",
    "    global_model = bmodel_global.build(89, 1)\n",
    "\n",
    "else:\n",
    "    exit('Error: unrecognized dataset')\n",
    "\n",
    "# display model summary\n",
    "print('Global Model Summary', global_model.summary())\n",
    "\n",
    "\n",
    "#commence global training loop\n",
    "    #loop through each node and create new local model\n",
    "\n",
    "global_average_weights = list()\n",
    "\n",
    "# loop to start the federated process\n",
    "for epoch in range(args.global_epochs):\n",
    "\n",
    "    print('\\nEpoch:', epoch, 'starting for Federated Learning\\n') \n",
    "    \n",
    "    scaled_local_weight_list = list()\n",
    "    \n",
    "    local_weight_name_list = list()\n",
    "\n",
    "    #randomize node data - using keys\n",
    "    node_names= list(nodes_batch.keys())\n",
    "    random.shuffle(node_names)\n",
    "    \n",
    "    # loop to start the nodes process\n",
    "    for node in node_names:\n",
    "\n",
    "        # BUILD MODEL\n",
    "        if args.dataset == 'multi-class':\n",
    "            # defining loss method, optimizer and learning rate\n",
    "            loss = 'sparse_categorical_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "            # initializing global model from the class\n",
    "            mmodel_global = MultiHomoModel()\n",
    "            # build a new model from the function\n",
    "            local_model = mmodel_global.build(89, 37)\n",
    "\n",
    "        elif args.dataset == 'triple-class':\n",
    "            # defining loss method, optimizer and learning rate\n",
    "            loss = 'sparse_categorical_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "            # initializing global model from the class\n",
    "            tmodel_global = TripleHomoModel()\n",
    "            # build a new model from the function\n",
    "            local_model = tmodel_global.build(89, 3)\n",
    "\n",
    "        elif args.dataset == 'binary-class':\n",
    "            # defining loss method, optimizer and learning rate\n",
    "            loss = 'binary_crossentropy'\n",
    "            metrics = ['accuracy']\n",
    "            optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "            # initializing global model from the class\n",
    "            bmodel_global = BinaryHomoModel()\n",
    "            # build a new model from the function\n",
    "            local_model = bmodel_global.build(89, 1)\n",
    "\n",
    "        else:\n",
    "            exit('Error: unrecognized dataset')\n",
    "\n",
    "        # initialize the model\n",
    "        local_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "        \n",
    "       # get the length of the average weights\n",
    "        length = len(global_average_weights)\n",
    "\n",
    "        # if length greater than zero get weights from the list of average weights otherwise from the global model \n",
    "        if length > 0:\n",
    "\n",
    "            # calling function to get the weights decrypted using secret key\n",
    "            global_weights = decryptWeights(global_average_weights)\n",
    "  \n",
    "        else:\n",
    "\n",
    "            global_weights = global_model.get_weights()\n",
    "\n",
    "        #set global model weight to the weights of the local model\n",
    "        local_model.set_weights(global_weights)\n",
    "\n",
    "        # -----------code to validate homo-morphic encryption----------\n",
    "\n",
    "        # get the model predictions using test data\n",
    "        y_pred = local_model.predict(X_test)\n",
    "\n",
    "        if args.dataset == 'binary-class':\n",
    "\n",
    "            # call function to get the threshold value\n",
    "            threshold = Find_Optimal_Cutoff(y_test,y_pred)\n",
    "   \n",
    "            # extracting predicted class labels in digits\n",
    "            y_pred_labels = np.where(y_pred > threshold, 1, 0) \n",
    "            \n",
    "        else:\n",
    "            # computes the index (label) of the highest predicted probability for each sample along axis 1\n",
    "            y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # computes the report \n",
    "        report = classification_report(y_test, y_pred_labels, zero_division=0)\n",
    "\n",
    "        print('\\n------------------Classification Report After Decryption--------------------\\n')\n",
    "\n",
    "        print(report)\n",
    "\n",
    "         # -----------code ends to validate homo-morphic encryption----------\n",
    "\n",
    "        print('Start', node, 'model training\\n')\n",
    "        \n",
    "        #fit local model with nodes data        \n",
    "        local_model.fit(nodes_batch[node], validation_data=(X_test, y_test), epochs=args.local_epochs, verbose=1)\n",
    "        \n",
    "        print('Stop', node, 'model training\\n')\n",
    "\n",
    "        # get the model predictions using test data\n",
    "        y_pred = local_model.predict(X_test)\n",
    "\n",
    "        if args.dataset == 'binary-class':\n",
    "\n",
    "            # call function to get the threshold value\n",
    "            threshold = Find_Optimal_Cutoff(y_test,y_pred)\n",
    "   \n",
    "            # extracting predicted class labels in digits\n",
    "            y_pred_labels = np.where(y_pred > threshold, 1, 0) \n",
    "            \n",
    "        else:\n",
    "            # computes the index (label) of the highest predicted probability for each sample along axis 1\n",
    "            y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # computes the report \n",
    "        report = classification_report(y_test, y_pred_labels, zero_division=0)\n",
    "\n",
    "        print('\\n------------------Classification Report Before Encryption--------------------\\n')\n",
    "\n",
    "        print(report)\n",
    "        \n",
    "        # call the function to get the scaling factor\n",
    "        scaling_factor = weight_scalling_factor(nodes_batch, node)\n",
    "\n",
    "        # get the weights from the model\n",
    "        unDict, namesW = getWeightsFromModel(local_model)\n",
    "        print (\"Weights dictionary created\\n\")\n",
    "        \n",
    "        # encrypt the model weights\n",
    "        t_start = time()\n",
    "        enDict = encryptWeights(unDict)\n",
    "        t_end = time()\n",
    "\n",
    "        print(f\"Encryption of the layers took {int(t_end - t_start)} seconds\\n\")\n",
    "        print (\"Encrypted Weights dictionary created\\n\")\n",
    "       \n",
    "        # calling function to scale the encrypted weights\n",
    "        scaled_weights = scale_model_weights_enc(enDict, scaling_factor)\n",
    "\n",
    "        # encrypted weights appended to the list\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "    \n",
    "    # call the function to get the encrypted average weights\n",
    "    global_average_weights = sum_scaled_weights_enc(scaled_local_weight_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
